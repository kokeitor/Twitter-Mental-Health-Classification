{"model": {"name": "microsoft/deberta-v3-base"}, "problem": {"labels_to_pred": [0, 1]}, "trainer": {"callbacks": {"EarlyStoppingCallback": {"early_stopping_patience": 3, "early_stopping_threshold": 0.0}}}, "metrics": {"type": {"f1": {"compute": true, "method": ["micro", "macro", "weighted", "binary"]}, "recall": {"compute": true, "method": ["micro", "macro", "weighted", "binary"]}, "MulticlassAccuracy": {"compute": true, "method": ["micro", "macro", "None"]}, "precision": {"compute": true, "method": ["micro", "macro", "weighted", "binary"]}}, "optimize": {"name": "f1_macro"}}, "training_args": {"dir_path": "./model/checkpoint", "eval_strategy": "steps", "report_to": "tensorboard", "save_strategy": "epoch", "learning_rate": 3e-05, "per_device_train_batch_size": 1, "per_device_eval_batch_size": 1, "num_train_epochs": 10, "weight_decay": 0.01, "warmup_steps": 2, "adam_epsilon": 1e-08, "load_best_model_at_end": true, "metric_for_best_model": "f1_macro", "gradient_accumulation_steps": 1, "warmup_ratio": 0.03, "fp16_full_eval": false, "fp16": false, "bf16": true}}